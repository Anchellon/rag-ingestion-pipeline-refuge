# ============================================
# Environment Configuration
# ============================================

# PostgreSQL Connection (required for Postgres ingestion pipeline)
DATABASE_URL=postgresql://postgres:password@localhost:5432/sheltertech

# Ollama Base URL
# This is the ONLY required environment variable.
# - WSL users: Use your WSL IP address (e.g., http://172.26.64.1:11434)
# - Mac/Linux/Windows: Use http://localhost:11434
# To find your WSL IP: ip addr show eth0 | grep -oP '(?<=inet\s)\d+(\.\d+){3}'
OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# Optional Overrides
# ============================================
# Uncomment and modify these if you need to override defaults from config.yaml

# LLM Model (default: llama3.2)
# OLLAMA_LLM_MODEL=llama3.2

# Embedding Model (default: nomic-embed-text)
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ChromaDB Directory (default: ./chroma_db)
# CHROMA_PERSIST_DIR=./chroma_db

# ChromaDB Collection Name (default: pdf-documents)
# CHROMA_COLLECTION_NAME=pdf-documents

# Chunk Size (default: 512)
# CHUNK_SIZE=512

# Chunk Overlap (default: 50)
# CHUNK_OVERLAP=50
